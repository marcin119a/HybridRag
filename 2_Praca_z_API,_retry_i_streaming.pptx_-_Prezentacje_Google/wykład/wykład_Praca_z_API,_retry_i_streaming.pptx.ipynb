{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /home/student/HybridRag/.venv/lib/python3.13/site-packages (5.49.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.121.2)\n",
      "Requirement already satisfied: ffmpy in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.36.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (2.3.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (2.11.10)\n",
      "Requirement already satisfied: pydub in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.14.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.49.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: fsspec in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio-client==1.13.3->gradio) (2025.10.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
      "Requirement already satisfied: requests in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "labels = [\"pozytywny\", \"neutralny\", \"negatywny\"]\n",
    "\n",
    "def predict_sentiment(text):  \n",
    "   result = classifier(text, candidate_labels=labels)\n",
    "   label = result['labels'][0]\n",
    "   score = result['scores'][0]\n",
    "   return f\"Sentyment: **{label}** (pewność: {score:.2%})\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "interface = gr.Interface(\n",
    "  fn=predict_sentiment,\n",
    "  inputs=gr.Textbox(lines=2, placeholder=\"Wpisz zdanie finansowe...\"),\n",
    "  outputs=\"text\",\n",
    "  title=\"Klasyfikator Sentimentu Finansowego (BART)\",\n",
    "  description=\"Ten interfejs wykorzystuje model BART w trybie zero-shot do klasyfikacji sentymentu w zdaniach finansowych. Etykiety: pozytywny, neutralny, negatywny.\"\n",
    ")\n",
    "\n",
    "interface.launch(server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Sure! Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"sk-\"  # ← wstaw swój klucz\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    " model=\"gpt-3.5-turbo\",\n",
    " messages=[\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Tell me a Joke!\"}\n",
    " ]\n",
    ")\n",
    "print(completion.choices[0].message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_zero_shot_classify(text, candidate_labels):\n",
    "   prompt = f\"Klasyfikuj następujący tekst do podanych kategorii: {candidate_labels}.\\nTekst: \\\"{text}\\\"\\n\\nKategoria:\"\n",
    "\n",
    "   completion = client.chat.completions.create(\n",
    "       model=\"gpt-3.5-turbo\",\n",
    "       messages=[ {\"role\": \"system\", \"content\": \"Jesteś asystentem, który klasyfikuje tekst do podanych kategorii. Odpowiadaj tylko nazwą kategorii.\"}, {\"role\": \"user\", \"content\": prompt}],\n",
    "       temperature=0\n",
    "   )\n",
    "   predicted_label = completion.choices[0].message.content.strip()\n",
    "   return f\"Kategoria: **{predicted_label}**\"\n",
    "labels = \"mieszkanie sprzedaż,mieszkanie wynajem,dom sprzedaż,dom wynajem\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>offer_url</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>num_images</th>\n",
       "      <th>street_address</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-wola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>ul. Księcia Janusza, Warszawa Wola, mazowieckie</td>\n",
       "      <td>Posiadam na sprzedaż przestronne mieszkanie na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-targ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Toruńska, Warszawa Targówek, mazowieckie</td>\n",
       "      <td>Na sprzedaż duże, jasne mieszkanie o powierzch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-bemo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>ul. Aleksandra Świętochowskiego, Warszawa Bemo...</td>\n",
       "      <td>Szukasz klimatycznego mieszkania w otoczeniu z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ocho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>ul. Bitwy Warszawskiej 1920 r., Warszawa Ochot...</td>\n",
       "      <td>Mieszkanie po generalnym remoncie. Do zamieszk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ursu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Tadeusza Hennela, Warszawa Ursus, mazowieckie</td>\n",
       "      <td>Zaoszczędź 16 000 zł i kup mieszkanie bez pośr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category  ...                                        description\n",
       "0  mieszkania_sprzedaz  ...  Posiadam na sprzedaż przestronne mieszkanie na...\n",
       "1  mieszkania_sprzedaz  ...  Na sprzedaż duże, jasne mieszkanie o powierzch...\n",
       "2  mieszkania_sprzedaz  ...  Szukasz klimatycznego mieszkania w otoczeniu z...\n",
       "3  mieszkania_sprzedaz  ...  Mieszkanie po generalnym remoncie. Do zamieszk...\n",
       "4  mieszkania_sprzedaz  ...  Zaoszczędź 16 000 zł i kup mieszkanie bez pośr...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "rag_worksop = kagglehub.dataset_download('martininf1n1ty/rag-workshop')\n",
    "\n",
    "df = pd.read_csv(f'{rag_worksop}/adresowo_offers_all_categories.csv').head(10)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kategoria: **mieszkanie sprzedaż**'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_zero_shot_classify(df['description'][0], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_pl']  = df['description'].apply(lambda x: openai_zero_shot_classify(x, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>offer_url</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>num_images</th>\n",
       "      <th>street_address</th>\n",
       "      <th>description</th>\n",
       "      <th>category_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-wola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>ul. Księcia Janusza, Warszawa Wola, mazowieckie</td>\n",
       "      <td>Posiadam na sprzedaż przestronne mieszkanie na...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-targ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Toruńska, Warszawa Targówek, mazowieckie</td>\n",
       "      <td>Na sprzedaż duże, jasne mieszkanie o powierzch...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-bemo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>ul. Aleksandra Świętochowskiego, Warszawa Bemo...</td>\n",
       "      <td>Szukasz klimatycznego mieszkania w otoczeniu z...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ocho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>ul. Bitwy Warszawskiej 1920 r., Warszawa Ochot...</td>\n",
       "      <td>Mieszkanie po generalnym remoncie. Do zamieszk...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ursu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Tadeusza Hennela, Warszawa Ursus, mazowieckie</td>\n",
       "      <td>Zaoszczędź 16 000 zł i kup mieszkanie bez pośr...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-wloc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>ul. Obywatelska, Warszawa Włochy, mazowieckie</td>\n",
       "      <td>Sprzedaż tylko bezpośrednia, pośrednikom dzięk...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-wloc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>ul. Trzcinowa, Warszawa Włochy, mazowieckie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kategoria: **Brak danych**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-bial...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>ul. Daniszewska, Warszawa Białołęka, mazowieckie</td>\n",
       "      <td>Na sprzedaż: 3-pokojowe mieszkanie z dużym bal...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ursy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>ul. Indiry Gandhi, Warszawa Ursynów, mazowieckie</td>\n",
       "      <td>Sprzedam bezpośrednio kawalerkę o powierzchni ...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-srod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>ul. Nowogrodzka, Warszawa Śródmieście, mazowie...</td>\n",
       "      <td>Do sprzedania mieszkanie w ścisłym centrum prz...</td>\n",
       "      <td>Kategoria: **mieszkanie sprzedaż**</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category  ...                         category_pl\n",
       "0  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "1  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "2  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "3  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "4  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "5  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "6  mieszkania_sprzedaz  ...          Kategoria: **Brak danych**\n",
       "7  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "8  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "9  mieszkania_sprzedaz  ...  Kategoria: **mieszkanie sprzedaż**\n",
       "\n",
       "[10 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transkrypcja ===\n",
      "Litwo, ojczyzno moja, Ty jesteś jak zdrowie, Ile Cię trzeba cenić, ten tylko się dowie, kto Cię stracił. Dziś piękność Twą w całej ozdobie widzę i opisuję, Bo tęsknię po Tobie, Panno Święta, co jasnej bronisz Częstochowy I w ostrej świecisz bramie. Ty, co gród zamkowy nowogródzki ochraniasz z jego wiernym ludem, Jak mnie, dziecko, do zdrowia powróciłaś cudem, Gdy od płaczącej matki pod Twoją opiekę, Ofiarowany martwą podniosłem powiekę I zaraz mogłem pieszo do Twych świątyń progu Iść za wrócone życie podziękować Bogu. Tak nas powrócisz cudem na ojczyzny łono, Tymczasem przenoś moją duszę utęsknioną Do tych pagórków leśnych, do tych łąk zielonych, Szeroko nad błękitnym niemnem rozciągnionych, Do tych pól malowanych zbożem rozmaitem, Wyzłacanych pszenicą posrebrzanych żytem, Gdzie bursztynowy świeżop gryka jak śnieg biała, Gdzie anieńskim rumieńcem dzięcielina pała, A wszystko przepasane jakby wstęgą miedzą zieloną, Na niej z rzadka ciche grusze siedzą.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "token = \"sk-\"\n",
    "# klient OpenAI\n",
    "client = OpenAI(api_key=token)\n",
    "\n",
    "# otwarcie pliku audio\n",
    "with open(\"ElevenLabs_2025-11-14T15_22_25_Jerzy_pvc_sp100_s50_sb75_se28_m2.mp3\", \"rb\") as audio_file:\n",
    "   transcription = client.audio.transcriptions.create(\n",
    "       model=\"whisper-1\",  # albo \"whisper-1\"\n",
    "       file=audio_file\n",
    "   )\n",
    "\n",
    "print(\"=== Transkrypcja ===\")\n",
    "print(transcription.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Transkrypcja (Whisper) ===\n",
      " Litwo, ojczyzno moja, ty jesteś jak zdrowie, ile cię trzeba cenić, ten tylko się dowie, kto cię stracił. Dziś piękność twą w całej ozdobie widzę i opisuję, bo tęsknie po tobie Panno Święta, co jasnej bronisz, częstochowy i w ostrej świecisz bramie. Ty, co grud zamkowy, nowogrócki ochraniasz z jego wiernym ludem, jak mnie dziecko do zdrowia powróciłaś cudem, Gdy odpłaczącej matki pod twoją opiekę, ofiarowany, martwą podniosłem powiekę i zaraz mogłem pieszo do twych świątyń progu iść zawrócone życie podziękować Bogu. Tak nas powrócisz, cudem na ojczyzny łono, tymczasem przenoś moją duszem utęsknioną do tych pagórków leśnych, do tych łąk zielonych, szeroko nad błękitnym niemnym rozciągnionych, do tych pól malowanych z bożem rozmaitem, wyzłacanych przenicom posrebrzanych rzytem, gdzie bursztynowy świeżop gryka jak śnieg biała, gdzie anieńskim rumieńcem dziencielina pała, a wszystko przepasane jakby wstęgą Miedzą zieloną na niej z rzadka ciche grusze siedzą.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# pipeline do transkrypcji audio (Whisper)\n",
    "pipe = pipeline(\n",
    "   task=\"automatic-speech-recognition\",\n",
    "   model=\"openai/whisper-small\",   # możesz zmienić na medium/large\n",
    ")\n",
    "\n",
    "# transkrypcja z pliku\n",
    "result = pipe(\"ElevenLabs_2025-11-14T15_22_25_Jerzy_pvc_sp100_s50_sb75_se28_m2.mp3\", return_timestamps=\"word\")\n",
    "\n",
    "print(\"=== Transkrypcja (Whisper) ===\")\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jWBp4tu1QPl"
   },
   "source": [
    "# Zadanie 1 – Klasyfikacja obrazów z CLIP\n",
    "\n",
    "Uruchom kod ładujący model CLIP (Contrastive Language–Image Pretraining).\n",
    "Model pozwala na klasyfikację obrazów bez trenowania — wystarczy podać opisy (prompty) kandydatów w języku naturalnym.\n",
    "\n",
    "#### Instrukcja\n",
    "\n",
    "* Przygotuj model CLIP do predykcji co jest na zdjęciu.\n",
    "\n",
    "* Wczytaj podany obraz scena.jpg z użyciem polecenia wget — możesz też użyć własnego pliku lub poniższego znaku drogowego.\n",
    "\n",
    "* Zdefiniuj własny zestaw etykiet tekstowych, np.:\n",
    "\n",
    "```python\n",
    "labels = [\n",
    "   \"a photo of a stop sign\",\n",
    "   \"a photo of a speed limit 50 sign\",\n",
    "   \"a photo of a no entry sign and a pedestrian crossing sign\",\n",
    "   \"a photo of a pedestrian crossing sign\",\n",
    "   \"a photo of a yield sign\",\n",
    "   \"a photo of a priority road sign\"\n",
    "]\n",
    "```\n",
    "\n",
    "Sprawdź, jak zmienia się predykcja modelu po zmianie promptów (np. dodaniu szczegółów:\n",
    "\"a photo of a red stop sign\" zamiast \"a photo of a traffic sign\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gdown) (4.14.2)\n",
      "Requirement already satisfied: filelock in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gdown) (3.20.0)\n",
      "Requirement already satisfied: requests[socks] in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, gdown\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [gdown]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PySocks-1.7.1 gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1762964366492,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "FatGV0WQsDSC",
    "outputId": "694d273f-0d13-43dc-beec-70d8aca21d39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1v5t_d03F2RKovxPoChTguKxuGwnXpgR7\n",
      "To: /home/student/HybridRag/2_Praca_z_API,_retry_i_streaming.pptx_-_Prezentacje_Google/wykład/scena.jpg\n",
      "100%|██████████| 136k/136k [00:00<00:00, 1.03MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'scena.jpg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1v5t_d03F2RKovxPoChTguKxuGwnXpgR7/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1v5t_d03F2RKovxPoChTguKxuGwnXpgR7'\n",
    "output_filename = 'scena.jpg'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "r-cmEIEF3Xc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "clip = pipeline(\n",
    "   task=\"zero-shot-image-classification\",\n",
    "   model=\"openai/clip-vit-base-patch32\",\n",
    "   dtype=torch.bfloat16,\n",
    "   device=0  # jeśli masz GPU; w przeciwnym razie użyj device=-1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "   \"a photo of a stop sign\",\n",
    "   \"a photo of a speed limit 50 sign\",\n",
    "   \"a photo of a no entry sign\",\n",
    "   \"a photo of a pedestrian crossing sign\",\n",
    "   \"a photo of a yield sign\",\n",
    "   \"a photo of a priority road sign\"\n",
    "]\n",
    "results = clip(\"scena.jpg\", candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.83984375, 'label': 'a photo of a pedestrian crossing sign'},\n",
       " {'score': 0.078125, 'label': 'a photo of a priority road sign'},\n",
       " {'score': 0.0537109375, 'label': 'a photo of a yield sign'},\n",
       " {'score': 0.0252685546875, 'label': 'a photo of a no entry sign'},\n",
       " {'score': 0.0034332275390625, 'label': 'a photo of a speed limit 50 sign'},\n",
       " {'score': 0.00098419189453125, 'label': 'a photo of a stop sign'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip(\"scena.jpg\", candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.76953125, 'label': 'modern finish'},\n",
       " {'score': 0.0810546875, 'label': 'traditional finish'},\n",
       " {'score': 0.0810546875, 'label': 'luxury finish'},\n",
       " {'score': 0.06298828125, 'label': 'basic finish'},\n",
       " {'score': 0.00457763671875, 'label': 'in need of renovation'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\n",
    "    'modern finish',\n",
    "    'traditional finish',\n",
    "    'in need of renovation',\n",
    "    'luxury finish',\n",
    "    'basic finish'\n",
    "]\n",
    "clip(\"image_00001.jpg\", candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6171875, 'label': 'modern finish'},\n",
       " {'score': 0.1767578125, 'label': 'basic finish'},\n",
       " {'score': 0.08349609375, 'label': 'in need of renovation'},\n",
       " {'score': 0.07373046875, 'label': 'traditional finish'},\n",
       " {'score': 0.050537109375, 'label': 'luxury finish'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\n",
    "    'modern finish',\n",
    "    'traditional finish',\n",
    "    'in need of renovation',\n",
    "    'luxury finish',\n",
    "    'basic finish'\n",
    "]\n",
    "clip(\"image_00002.jpg\", candidate_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkQbrCtm1sNQ"
   },
   "source": [
    "\n",
    "### Zadanie 2 – Transkrypcja audio z OpenAI\n",
    "\n",
    "* Otwórz plik audio Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3.\n",
    "\n",
    "* Wykonaj transkrypcję przy pomocy API OpenAI (gpt-4o-mini-transcribe lub whisper-1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1762964258096,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "28ef84e7",
    "outputId": "188d0a40-d666-4aea-e02c-c2a2b2719c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc\n",
      "To: /content/Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3\n",
      "100%|██████████| 495k/495k [00:00<00:00, 91.9MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc'\n",
    "output_filename = 'Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBn8oH_H1s1n"
   },
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMrgRTV61tKI"
   },
   "source": [
    "\n",
    "### Zadanie 3 – Transkrypcja audio z modelem HuggingFace (Whisper)\n",
    "\n",
    "* Uruchom pipeline automatic-speech-recognition z modelem openai/whisper-small.\n",
    "\n",
    "Porównaj wynik transkrypcji z wynikiem API OpenAI z Zadania 3.\n",
    "\n",
    "Odpowiedz na pytania:\n",
    "\n",
    "* Który model lepiej rozpoznał tekst?\n",
    "\n",
    "* Czy występują różnice w interpunkcji i zapisie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_XJIqH6rl4r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlwtQAEzkmCV"
   },
   "source": [
    "\n",
    "### Zadanie 4. Użycie PaddleOCR do analizy obrazu w języku polskim\n",
    "\n",
    "Korzystając z biblioteki `PaddleOCR`:\n",
    "\n",
    "1. Wczytaj obrazek z polskim tekstem (np. plik `Screenshot 2025-11-12 at 15.25.56.png`).\n",
    "2. Uruchom OCR z parametrem `lang='pl'`.\n",
    "3. Wypisz rozpoznany tekst w konsoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 2021,
     "status": "ok",
     "timestamp": 1762964455367,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "7kZuiV-Hwe-t",
    "outputId": "00c4f645-5ce5-4fbf-b3d3-75ef04357424"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1npxluHj4P5NVmFes5opL8k16-sWGm2rH\n",
      "To: /home/student/HybridRag/2_Praca_z_API,_retry_i_streaming.pptx_-_Prezentacje_Google/wykład/Screenshot 2025-11-12 at 15.25.56.png\n",
      "100%|██████████| 1.73M/1.73M [00:00<00:00, 6.97MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Screenshot 2025-11-12 at 15.25.56.png'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1npxluHj4P5NVmFes5opL8k16-sWGm2rH/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1npxluHj4P5NVmFes5opL8k16-sWGm2rH'\n",
    "output_filename = 'Screenshot 2025-11-12 at 15.25.56.png'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlepaddle\n",
      "  Downloading paddlepaddle-3.2.1-cp313-cp313-manylinux1_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting paddleocr\n",
      "  Downloading paddleocr-3.3.2-py3-none-any.whl.metadata (55 kB)\n",
      "Requirement already satisfied: httpx in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (2.3.5)\n",
      "Collecting protobuf>=3.20.2 (from paddlepaddle)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: Pillow in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (11.3.0)\n",
      "Collecting opt_einsum==3.3.0 (from paddlepaddle)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: networkx in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (3.5)\n",
      "Requirement already satisfied: typing_extensions in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (4.15.0)\n",
      "Requirement already satisfied: safetensors>=0.6.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlepaddle) (0.6.2)\n",
      "Collecting paddlex<3.4.0,>=3.3.0 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading paddlex-3.3.9-py3-none-any.whl.metadata (79 kB)\n",
      "Requirement already satisfied: PyYAML>=6 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddleocr) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddleocr) (2.32.5)\n",
      "Collecting aistudio-sdk>=0.3.5 (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading aistudio_sdk-0.3.8-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting chardet (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting colorlog (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.36.0)\n",
      "Collecting modelscope>=1.28.0 (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading modelscope-1.31.0-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: packaging in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (25.0)\n",
      "Requirement already satisfied: pandas>=1.3 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.3.3)\n",
      "Collecting prettytable (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading prettytable-3.17.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting py-cpuinfo (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pydantic>=2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.11.10)\n",
      "Collecting PyYAML>=6 (from paddleocr)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting ruamel.yaml (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ujson (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading ujson-5.11.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
      "Collecting imagesize (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opencv-contrib-python==4.10.0.84 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pyclipper (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pypdfium2>=4 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Collecting python-bidi (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading python_bidi-0.6.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting shapely (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading shapely-2.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: psutil in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (7.1.3)\n",
      "Requirement already satisfied: tqdm in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (4.67.1)\n",
      "Collecting bce-python-sdk (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading bce_python_sdk-0.9.52-py3-none-any.whl.metadata (416 bytes)\n",
      "Requirement already satisfied: click in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (8.3.1)\n",
      "Requirement already satisfied: setuptools in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from modelscope>=1.28.0->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (80.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from modelscope>=1.28.0->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests->paddleocr) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests->paddleocr) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from requests->paddleocr) (2025.11.12)\n",
      "Collecting pycryptodome>=3.8.0 (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting future>=0.6.0 (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: anyio in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpx->paddlepaddle) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpx->paddlepaddle) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from huggingface-hub->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in /home/student/HybridRag/.venv/lib/python3.13/site-packages (from prettytable->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.2.14)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
      "  Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Downloading paddlepaddle-3.2.1-cp313-cp313-manylinux1_x86_64.whl (189.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading paddleocr-3.3.2-py3-none-any.whl (86 kB)\n",
      "Downloading paddlex-3.3.9-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.5/759.5 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aistudio_sdk-0.3.8-py3-none-any.whl (62 kB)\n",
      "Downloading modelscope-1.31.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bce_python_sdk-0.9.52-py3-none-any.whl (390 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading prettytable-3.17.0-py3-none-any.whl (34 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyclipper-1.3.0.post6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (962 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "Downloading ruamel_yaml_clib-0.2.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.1/782.1 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.11.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, py-cpuinfo, ujson, shapely, ruamel.yaml.clib, PyYAML, pypdfium2, pycryptodome, protobuf, prettytable, opt_einsum, opencv-contrib-python, imagesize, future, colorlog, chardet, ruamel.yaml, modelscope, bce-python-sdk, paddlepaddle, aistudio-sdk, paddlex, paddleocr\n",
      "\u001b[2K  Attempting uninstall: PyYAML90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [shapely]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [shapely]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [shapely]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [shapely]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [paddleocr]24\u001b[0m [paddleocr]dk]k]python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.2 aistudio-sdk-0.3.8 bce-python-sdk-0.9.52 chardet-5.2.0 colorlog-6.10.1 future-1.0.0 imagesize-1.4.1 modelscope-1.31.0 opencv-contrib-python-4.10.0.84 opt_einsum-3.3.0 paddleocr-3.3.2 paddlepaddle-3.2.1 paddlex-3.3.9 prettytable-3.17.0 protobuf-6.33.1 py-cpuinfo-9.0.0 pyclipper-1.3.0.post6 pycryptodome-3.23.0 pypdfium2-5.0.0 python-bidi-0.6.7 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.15 shapely-2.1.2 ujson-5.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlepaddle paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "m1IaJUop3vnq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/student/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/student/.paddlex/official_models/latin_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARBUCKS ZMIEÑ DZIEN NALEPSZE CARA MACC Starbucks Cheled Lont a. Czekamy na Ciebie wled LVBET BET Google Maps Yiaaa\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR(\n",
    "   use_doc_orientation_classify=False,\n",
    "   use_doc_unwarping=False,\n",
    "   use_textline_orientation=False,\n",
    "   lang='pl')\n",
    "\n",
    "# Run OCR inference on a sample image\n",
    "result = ocr.predict(\n",
    "   input=\"Screenshot 2025-11-12 at 15.25.56.png\")\n",
    "\n",
    "extracted_text = \"\"\n",
    "if result and result[0] and 'rec_texts' in result[0]:\n",
    "   extracted_text = \" \".join(result[0]['rec_texts'])\n",
    "\n",
    "print(extracted_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsWBXIFR5_vV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "executionInfo": {
     "elapsed": 5339,
     "status": "ok",
     "timestamp": 1758639251635,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -120
    },
    "id": "PXkuvaZOEN_g",
    "outputId": "192e86a2-063c-4194-af3e-1b61fd022803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'rag-workshop' dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"dzialki_wynajem\",\n          \"domy_sprzedaz\",\n          \"mieszkania_wynajem\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offer_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"https://adresowo.pl/o/pokoj-wynajem-warszawa-srodmiescie-ul-krasiczynska-n0z9f7\",\n          \"https://adresowo.pl/o/dzialka-rekreacyjna-warszawa-ul-piastow-slaskich-x9t1v6\",\n          \"https://adresowo.pl/o/mieszkanie-wynajem-warszawa-muranow-ul-stawki-1-pokoj-d7r9s6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"currency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_images\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 36,\n        \"num_unique_values\": 23,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"street_address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 89,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-60548d19-fea3-49d1-960c-10cfb8b68999\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>offer_url</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>num_images</th>\n",
       "      <th>street_address</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-wola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>ul. Księcia Janusza, Warszawa Wola, mazowieckie</td>\n",
       "      <td>Posiadam na sprzedaż przestronne mieszkanie na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-targ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Toruńska, Warszawa Targówek, mazowieckie</td>\n",
       "      <td>Na sprzedaż duże, jasne mieszkanie o powierzch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-bemo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>ul. Aleksandra Świętochowskiego, Warszawa Bemo...</td>\n",
       "      <td>Szukasz klimatycznego mieszkania w otoczeniu z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ocho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>ul. Bitwy Warszawskiej 1920 r., Warszawa Ochot...</td>\n",
       "      <td>Mieszkanie po generalnym remoncie. Do zamieszk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mieszkania_sprzedaz</td>\n",
       "      <td>https://adresowo.pl/o/mieszkanie-warszawa-ursu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>ul. Tadeusza Hennela, Warszawa Ursus, mazowieckie</td>\n",
       "      <td>Zaoszczędź 16 000 zł i kup mieszkanie bez pośr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60548d19-fea3-49d1-960c-10cfb8b68999')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-60548d19-fea3-49d1-960c-10cfb8b68999 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-60548d19-fea3-49d1-960c-10cfb8b68999');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-86740137-95c4-4899-ac1c-9684ac36554b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86740137-95c4-4899-ac1c-9684ac36554b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-86740137-95c4-4899-ac1c-9684ac36554b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              category                                          offer_url  \\\n",
       "0  mieszkania_sprzedaz  https://adresowo.pl/o/mieszkanie-warszawa-wola...   \n",
       "1  mieszkania_sprzedaz  https://adresowo.pl/o/mieszkanie-warszawa-targ...   \n",
       "2  mieszkania_sprzedaz  https://adresowo.pl/o/mieszkanie-warszawa-bemo...   \n",
       "3  mieszkania_sprzedaz  https://adresowo.pl/o/mieszkanie-warszawa-ocho...   \n",
       "4  mieszkania_sprzedaz  https://adresowo.pl/o/mieszkanie-warszawa-ursu...   \n",
       "\n",
       "   price  currency  num_images  \\\n",
       "0    NaN       NaN           4   \n",
       "1    NaN       NaN          14   \n",
       "2    NaN       NaN          20   \n",
       "3    NaN       NaN           6   \n",
       "4    NaN       NaN          14   \n",
       "\n",
       "                                      street_address  \\\n",
       "0    ul. Księcia Janusza, Warszawa Wola, mazowieckie   \n",
       "1       ul. Toruńska, Warszawa Targówek, mazowieckie   \n",
       "2  ul. Aleksandra Świętochowskiego, Warszawa Bemo...   \n",
       "3  ul. Bitwy Warszawskiej 1920 r., Warszawa Ochot...   \n",
       "4  ul. Tadeusza Hennela, Warszawa Ursus, mazowieckie   \n",
       "\n",
       "                                         description  \n",
       "0  Posiadam na sprzedaż przestronne mieszkanie na...  \n",
       "1  Na sprzedaż duże, jasne mieszkanie o powierzch...  \n",
       "2  Szukasz klimatycznego mieszkania w otoczeniu z...  \n",
       "3  Mieszkanie po generalnym remoncie. Do zamieszk...  \n",
       "4  Zaoszczędź 16 000 zł i kup mieszkanie bez pośr...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "rag_worksop = kagglehub.dataset_download('martininf1n1ty/rag-workshop')\n",
    "\n",
    "df = pd.read_csv(f'{rag_worksop}/adresowo_offers_all_categories.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPeQe11TETOx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6+HkAAVpJWXG4pqRNH0/o",
   "provenance": [
    {
     "file_id": "1AN1OTGWecq5MHBZEBuOSJ_LcK76WnfZT",
     "timestamp": 1758636545869
    },
    {
     "file_id": "1Sx56wlJGgeSW6RFCNReh3cEfUKgJSJNJ",
     "timestamp": 1758635994188
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
