{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jWBp4tu1QPl"
   },
   "source": [
    "# Zadanie 1 – Klasyfikacja obrazów z CLIP\n",
    "\n",
    "Uruchom kod ładujący model CLIP (Contrastive Language–Image Pretraining).\n",
    "Model pozwala na klasyfikację obrazów bez trenowania — wystarczy podać opisy (prompty) kandydatów w języku naturalnym.\n",
    "\n",
    "#### Instrukcja\n",
    "\n",
    "* Przygotuj model CLIP do predykcji co jest na zdjęciu.\n",
    "\n",
    "* Wczytaj podany obraz scena.jpg z użyciem polecenia wget — możesz też użyć własnego pliku lub poniższego znaku drogowego.\n",
    "\n",
    "* Zdefiniuj własny zestaw etykiet tekstowych, np.:\n",
    "\n",
    "```python\n",
    "labels = [\n",
    "   \"a photo of a stop sign\",\n",
    "   \"a photo of a speed limit 50 sign\",\n",
    "   \"a photo of a no entry sign and a pedestrian crossing sign\",\n",
    "   \"a photo of a pedestrian crossing sign\",\n",
    "   \"a photo of a yield sign\",\n",
    "   \"a photo of a priority road sign\"\n",
    "]\n",
    "```\n",
    "\n",
    "Sprawdź, jak zmienia się predykcja modelu po zmianie promptów (np. dodaniu szczegółów:\n",
    "\"a photo of a red stop sign\" zamiast \"a photo of a traffic sign\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1762964366492,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "FatGV0WQsDSC",
    "outputId": "694d273f-0d13-43dc-beec-70d8aca21d39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1v5t_d03F2RKovxPoChTguKxuGwnXpgR7\n",
      "To: /content/scena.jpg\n",
      "100%|██████████| 136k/136k [00:00<00:00, 77.5MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'scena.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1v5t_d03F2RKovxPoChTguKxuGwnXpgR7/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1v5t_d03F2RKovxPoChTguKxuGwnXpgR7'\n",
    "output_filename = 'scena.jpg'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-cmEIEF3Xc8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkQbrCtm1sNQ"
   },
   "source": [
    "\n",
    "### Zadanie 2 – Transkrypcja audio z OpenAI\n",
    "\n",
    "* Otwórz plik audio Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3.\n",
    "\n",
    "* Wykonaj transkrypcję przy pomocy API OpenAI (gpt-4o-mini-transcribe lub whisper-1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1762964258096,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "28ef84e7",
    "outputId": "188d0a40-d666-4aea-e02c-c2a2b2719c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc\n",
      "To: /content/Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3\n",
      "100%|██████████| 495k/495k [00:00<00:00, 91.9MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1_518XiGq9hF9-6umkHIkAEGlXMpmQqvc'\n",
    "output_filename = 'Alloy_tts-1_1x_2024-10-28T09_42_03-535Z.mp3'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBn8oH_H1s1n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMrgRTV61tKI"
   },
   "source": [
    "\n",
    "### Zadanie 3 – Transkrypcja audio z modelem HuggingFace (Whisper)\n",
    "\n",
    "* Uruchom pipeline automatic-speech-recognition z modelem openai/whisper-small.\n",
    "\n",
    "Porównaj wynik transkrypcji z wynikiem API OpenAI z Zadania 3.\n",
    "\n",
    "Odpowiedz na pytania:\n",
    "\n",
    "* Który model lepiej rozpoznał tekst?\n",
    "\n",
    "* Czy występują różnice w interpunkcji i zapisie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_XJIqH6rl4r"
   },
   "outputs": [],
   "source": [
    "%sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlwtQAEzkmCV"
   },
   "source": [
    "\n",
    "### Zadanie 4. Użycie PaddleOCR do analizy obrazu w języku polskim\n",
    "\n",
    "Korzystając z biblioteki `PaddleOCR`:\n",
    "\n",
    "1. Wczytaj obrazek z polskim tekstem (np. plik `Screenshot 2025-11-12 at 15.25.56.png`).\n",
    "2. Uruchom OCR z parametrem `lang='pl'`.\n",
    "3. Wypisz rozpoznany tekst w konsoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 2021,
     "status": "ok",
     "timestamp": 1762964455367,
     "user": {
      "displayName": "Marcin Wierzbiński",
      "userId": "17804358760504223388"
     },
     "user_tz": -60
    },
    "id": "7kZuiV-Hwe-t",
    "outputId": "00c4f645-5ce5-4fbf-b3d3-75ef04357424"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1npxluHj4P5NVmFes5opL8k16-sWGm2rH\n",
      "To: /content/Screenshot 2025-11-12 at 15.25.56.png\n",
      "100%|██████████| 1.73M/1.73M [00:00<00:00, 147MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Screenshot 2025-11-12 at 15.25.56.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link do danych: https://drive.google.com/file/d/1npxluHj4P5NVmFes5opL8k16-sWGm2rH/view?usp=sharing\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1npxluHj4P5NVmFes5opL8k16-sWGm2rH'\n",
    "output_filename = 'Screenshot 2025-11-12 at 15.25.56.png'\n",
    "\n",
    "gdown.download(id=file_id, output=output_filename, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPeQe11TETOx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6+HkAAVpJWXG4pqRNH0/o",
   "provenance": [
    {
     "file_id": "1AN1OTGWecq5MHBZEBuOSJ_LcK76WnfZT",
     "timestamp": 1758636545869
    },
    {
     "file_id": "1Sx56wlJGgeSW6RFCNReh3cEfUKgJSJNJ",
     "timestamp": 1758635994188
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
